\chapter{Conclusion and Future Work} % Main chapter title

\label{chapter:conclusion} 

This dissertation describes three in-game element recommendation systems (i.e., starting items, characters, and opponents, respectively) designed to apply in the pre-match stage for indirectly or directly for improving player engagement based on theoretical foundations or data-driven approaches. 

The starting item and character recommendation systems, within the context of one-vs-one and team-vs-team settings respectively, attempt to identify winning-effective in-game elements efficiently from a large amount of candidates. Their usefulness is based on the assumption that presenting winning-effective in-game elements to players could improve their competence, and theoretical foundations such as Self-Determination Theory and Flow that improving player competence leads to better engagement. Thus, the starting item and character recommendation systems can be seen as an indirect approach to improve player engagement. We conducted experiments and showed that our proposed systems are able to recommend equally or more winning-effective in-game elements than previous methods with computational resources efficient enough for large-scale or real-time usage. 

The third system aims to directly optimize player engagement through matchmaking, i.e., recommendations of opponents. We define player engagement quantitatively as churn risk and rely on data-driven approaches to model player engagement, based on which the  matching of opponents optimal for overall player engagement is located using a graph matching algorithm. As far as we know, this is the first system that has formally treated matchmaking as an optimization problem for player engagement. We build a simulated system using real game data, showing significant advantages of the proposed matchmaking system in retaining players over existing methods.


% The starting item and character recommendation systems manifest how match outcomes can be swayed positively from one side of player(s) in match-based video games. They are seen as indirect means of improving player engagement because the trigger of recommendations may need to be decided by other systems, which we did not investigate further in this thesis. Exemplifying how and how much match outcomes should be influenced for a population of players, the opponent recommendation is seen as a direct means of improving player engagement because the system directly optimizes the objective function in which expected match outcomes after opponent matching maximizes the all participated opponents. 

We note several limitations of our works and wish to address them in the future (with Point 1 $\sim$ 4, 5 $\sim$ 7, and 8 $\sim$ 10 being relevant to our recommendation systems for starting items, characters, and opponents, respectively):

\hl {these points come from every paper's "limitation" part}
\begin{enumerate}
\item Q-DeckRec relies on AI proxies which are supposed to accurately model players' play styles. The current used AI proxy is only based on a greedy heuristic rather than trained on human play traces. Therefore, the optimal decks obtained in our experiments cannot be directly recommended to human players. Training human-like AI proxies and integrating them to Q-DeckRec will be an important direction in our future works. 

\item We can also improve sample efficiency of Q-DeckRec. Currently, each training episode starts with a random initialized state. Were it generated from a card distribution learned from real matches, Q-DeckRec might focus on exploring in a smaller but more useful state space. 

\item As online CCGs often release patches to introduce new cards and modify existing cards' in-game effects, we would like to investigate how Q-DeckRec can transfer and update its knowledge without totally re-training the model~\cite{taylor2009transfer}.

\item We have only investigated the deck recommendation problem towards a single opponent. There remains a question of how to design the feature representation of state-action pairs in Q-DeckRec if the problem is extended to recommend winning-effective decks against a group of opponent decks. Naive feature representations for the opponent deck group could be simply concatenating each of the opponents' deck representation vector in the group. However this creates a large feature space which may not be efficient for learning. A more advanced feature representation may represent the opponent deck group in a continuous vector space, similar to word-embedding techniques from Natural Language Processing (NLP)~\cite{mikolov2013distributed}. We intend to investigate all of these feature representation approaches in the future.

\item One limitation of DraftArtist is that we have not considered player-specific information, such as player skills in their selected characters, when recommending characters. It is possible that a character recommended by our algorithm, which is based solely on the current hero line-up, may not be played well by a player who is not familiar with it. Our algorithm can be extended to integrate player skills, by augmenting the game state with player information and training a more advanced win rate predictor as the reward function which takes as input both hero picks and player-specific information, once we have access to needed player-specific data.

\item Were hero pick sequences from real match data available, we would integrate them as prior information to improve the tree policy and default policy in MCTS, thereby improving capabilities to build search trees more effectively and efficiently~\cite{gelly2007combining,chaslot2009adding}. 

\item We would also like to investigate how our recommendation systems can be customized to account for additional drafting rules and extended to other real-world scenarios such as player drafting in sports~\cite{staw1995sunk}. 


\item So far we have discussed EOMM in 1-vs-1 game scenarios. This framework also applies to match-based games that involve teams of players, where every component needs to be extended with additional care. The skill model can be simply applied to a team by adding up skills for all team members~\cite{herbrich:trueskill}. For churn prediction, we can use the same idea that one player's churn risk is conditionally independent with other players' states given that their influence on the player's own state, such as the game outcome, is known. Last, the minimum weight perfect matching algorithms for pairs are no longer applicable. Instead of a pair assignment, we seek a grouping assignment on a complete graph. A related area to investigate is perfect matching in hypergraphs~\cite{berge1984hypergraphs}, where an edge can connect more than two vertices. 

%Furthermore, EOMM is not even limited to games. In broad applications, such as friend connection in a social network and 1-on-1 tutoring in online education, EOMM's formulation and optimization techniques still apply.

\item We expect EOMM equipped with more advanced models, such as skill model and churn model, can have higher optimal bound. We will explore EOMM performance in more realistic situations, where practical restrictions are applied, such as network connectivity, regions and friend/black lists. More restrictions would result in fewer edges in the constructed graph of EOMM and perhaps faster algorithms for solving minimum perfect weight matching. 

\item We will explore EOMM in multi-player games with more than two players involved and efficient algorithms analogous to perfect matching algorithms within hypergraphs.
\end{enumerate}

We also envision several future directions for continuing the research in in-game element recommendation systems for improving player competence and player engagement. First, we are eagerly looking for testing our systems online. Currently, none of our proposed system has been thoroughly tested online for player engagement. Admittedly, this would require deep cooperation with developers and companies of existing games. Second, besides starting items, characters, and opponents, we would like to investigate recommendation systems on more kinds of in-game elements, including but not limited to weapons, maps, play strategies, teammates, and buildings. Each kind of in-game elements may require specific treatment for recommendations. Third, we have not investigated enough when we should deliver recommendations for starting items and characters. We expect these recommendations should be triggered by churn models which determine which players are in need of help otherwise would quit the game. However, more empirical experiments need to be conducted on recommendation systems integrated with such triggering models. Lastly, we would like to design a unified recommendation system which could make central decisions on recommendations of various in-game elements for improving overall engagement of each player. 

% Like most of existing recommendation systems, each of the recommendation systems proposed in my thesis deals with only a specific type of in-game element. A more ambitious goal is
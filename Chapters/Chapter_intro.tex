% Chapter Template

\chapter{Introduction} % Main chapter title

\label{chapter:intro} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}

\section{Motivation and Research Question}\label{chap1:motiv}

The world has witnessed a gallery of video games that manage to make people addicted into playing day and night. The series of \textit{Super Mario Bros.} (Nintendo Co. Ltd) have sold over 160 million since the 1980s \cite{mariosale}. Players enjoy the excitement and fulfillment of passing through game levels designed with various challenges. \textit{League of Legends}, a 5-vs-5 online competitive game, has 90 million users registered, 27 million unique daily players and 7.5 million concurrent users at peak \cite{lol_fanbase,lol_27million}. The game is characteristized by competition, collaboration and strategies that players are hard to experience in the real world. Recently, \textit{Pok\'{e}mon Go} (Niantic, Inc.) has swept the globe with more than 500 million downloads \cite{pokemongo}, triggering the crowd to walk on the street to interact with the game. At the same time, the viewership of video games has also grown rapidly. e-Sports, a subset of highly competitive video games, was estimated to have hundreds of million viewership in 2017 and projected to still grow at 12\% each year~\cite{superdata2017}. Besides being commonly perceived as a means of entertainment, video games have also been utilized for various purposes, such as promoting aesthetic appreciation~\cite{jarvinen2008understanding}, health awareness~\cite{shiyko2016effects}, science learning~\cite{cooper2013increasing}, and socialization~\cite{ferguson2013friends}.

As video games continue to penetrate an increasing number of fields for improving the wellness of our society, one question arises naturally: \textit{how can we keep players engaged?} Indeed, without player engagement, video games could not serve their purposes ranging from entertainment to promoting science learning. Poor player engagement would not only hurt the gaming experience of players, but also revenues by game companies, as nowadays video games have become a highly valuable market worth hundreds of billions of dollars~\cite{today_video_game_market}.

Therefore, player engagement becomes a critical topic for research, with its importance reflected by a large body of literatures (e.g.,~\cite{boyle2012engagement,schoenau2011player,choi2004people,brockmyer2009development}). We adopt the most straightforward definition of player engagement as the "continuation desire" to play a game repeatedly during play or over a longer period of time~\cite{schoenau2011player}, while the desire may be explained by numerous different theories; famous examples include Self-Determination theory~\cite{przybylski2010motivational,ryan2006motivational} which associates players' motives to continue playing with their needs for competence, autonomy and relatedness, and Flow theory~\cite{sweetser2005gameflow,flow1990psychology,chen2007flow} which argues that one important ingredient of player engagement is the optimal match between challenges in the game and their skills.

While player engagement could derive from many factors as suggested by the rich literature, one factor can be deduced from numerous theories that has a close relationship with player engagement: \textbf{game outcomes}. In my thesis, I refer a game outcome generally to any possible outcome in a game indicating the player's progress, such as wins, losses, level-ups, and milestones achieved. According to Flow theory~\cite{sweetser2005gameflow,flow1990psychology,chen2007flow}, part of player engagement comes from challenges which match the player's skill level and keep at an appropriate pace. Similarly, competence in Self-Determination theory~\cite{przybylski2010motivational,ryan2006motivational} refers to the need for challenge and feelings of effectance~\cite{deci1985intrinsic,white1959motivation} which drives players' intrinsic motivation to engage in the game.  Theories have also pointed out the pursuit of victory and achievement as a reason of engagement~\cite{schoenau2011player,yee2006motivations,sherry2006video,wu2010falling,lazzaro2004we}. All these theoretical studies show that monotonous game outcomes such as consecutive losses or wins are not desirable because they indicate consistent over-/under-challenging player experience and raise the importance of carefully maintaining an appropriate sequence of game outcomes for players.

% \footnote{Due to confidential issues, we cannot reveal the title of the game.}
We also use an empirical example drawn from real-world data to evidence the close relationship between game outcomes and player engagement. In Table~\ref{tab:churnrate}, we show that churn risks vary drastically upon players' recent game outcomes in a real-world popular PvP game. Here, the game is played match by match, with each having one of three possible outcomes - win, lose or draw, and churn risk, a common quantitative measurement of player engagement, is the ratio of the players who stop playing within a certain period after a match. What we discover are that: (1) monotonous losses result in the worst churn rate (5.1\%), which can be related to frustration caused by repeated losses; (2) more interestingly, monotonous wins is not the best game outcome sequence; rather, the lowest churn rate is mostly realized when the last three game outcomes show "some promise" - e.g., no win in the first two matches and finally a win in the third match.                   

\begin{table}
\centering
\caption{
Average churn risks vary drastically upon players' recent three match outcomes (\emph{(W)in}, \emph{(L)ose} or \emph{(D)raw}). Data is from a popular PvP game made by Electronic Arts, Inc. Churn risk is measured by the ratio of the players who stop playing within a period time (7 days in this table) after a match. The churn risk of some states with repeated losses (5.1\%) is almost twice as much as those of other "safer" states (2.6\%-2.7\%).
} \label{tab:churnrate}
\vspace{2mm}
\begin{tabular}{|c|c|}
\hline
Last 3 Outcomes & Churn Risk                      \\ \hline
DLW $|$ LLW $|$ LDW $|$ DDD      &  2.6\% - 2.7\%        \\
... & ...  \\
WWW   &  3.7\% \\
... & ... \\
DLL $|$ LWL $|$ LDL  &  4.6\% - 4.7\%  \\
WWL & 4.9\% \\
LLL & 5.1\% \\
\hline
\end{tabular}
\end{table}

The close relationship between game outcomes and player engagement based on theoretical and empirical findings motivate this thesis. Following the first question that \textit{how can we keep players engaged?}, we tend to ask the next question: \textit{how can we influence game outcomes as a means of keeping players engaged?}

To influence game outcomes as a means of keeping player engagement, we could dynamically change \textit{in-game elements}, which generally refers to any kind of element that constitutes a game~\cite{ralph2015toward,fullerton2008game} ranging from game artifacts (e.g., levels, maps, and weapons) to players themselves. This can be achieved by game designers adding heuristics into game design representing their subjective beliefs about what in-game elements are good or bad for player engagement. For instance, certain in-game equipment boosts is designed to be present only in disadvantageous situations to prevent particular players from losing. However, such a method requires heavy domain expertise and lacks scalability and variability. 

To alleviate the enormous cost and effort associated with manual design, an algorithmic alternative for influencing game outcomes is through recommendation systems~\cite{medler2011using}, which provide to players predictions and recommendations of in-game elements adaptive to their personal states (e.g., skills and preferences).  Recommendation system techniques originate from web applications, with the aim to ease information overload and retrieve the most relevant information to users for providing personalized services~\cite{isinkaye2015recommendation,bobadilla2013recommender,resnick1997recommender,adomavicius2005toward}. In video games, players could also face a number of, possibly inundated, choices of in-game elements and recommendation systems could facilitate their decision making and influence consequent game outcomes. For example, it may pose challenge to inexperienced players for selecting winning-effective characters~\cite{hanke2017reco,summerville2017reco} or items~\cite{garcia2016evolutionary,bjorke2017deckbuilding} from a large number of candidates and recommendation systems could be applied here to offer personalized recommendations on characters and items that help them win with a higher chance.

% The recommendations, once adopted by the players, could start to influence game outcomes as the recommendation system predicts.
% , where the in-game content specifically refers to any aspect that constitutes the game itself (e.g., levels, maps, and weapons)

% while recommendation systems do not have the access to generate or modify in-game content and only operate on in-game content that the player could make a choice about. For example, an upcoming level in a game could be automatically generated by PCG entailing pre-defined difficulty and themes; however, if the player is not offered to interact with the difficulty and theme configuration of the upcoming level, then there is no recommendation that could be made regarding the upcoming level's content. On the other hand, a recommendation system could recommend to players, for example, suitable play styles~\cite{thue2007interactive,magerko2008intelligent} and skill-competitive human opponents~\cite{Delalleau2012,herbrich:trueskill}, which are not able to be generated by PCG. At the same time, we also acknowledge the interconnectivity between PCG and recommendation systems: technologies used in PCG may be useful to search for optimal recommendations in recommendation systems, or vice versa. 

Although human-based design and recommendation systems are equally valid ways to influence game outcomes as a means of keeping player engagement, I focus on recommendation systems in this thesis because they can be deployed in a scalable, just-in-time, and on-demand fashion with less design knowledge required. This choice further narrows my research question onto \textit{how can we use recommendation systems to influence game outcomes as a means of keeping players engaged?}

% First, it has always been difficult to access sensitive game data or related software tools for video game research. Through research collaboration and industry internships in the past years, I have spent significant efforts in gathering data and relevant tools which facilitate my research in modeling player and verifying the quality of different recommendation systems. These data and tools, however, could not give me access to generate content in any particular game that I can iteratively test the performance of different PCG algorithms. Second, compared to extensive research in PCG for video games and recommendation systems outside the field of video games, recommendation systems for in-game content in video games have had less attention, indicating much room for improvement. The more detailed motivation for each project is laid out as follows. 

Since my thesis cannot exhaust all scenarios where recommendation systems are applicable in video games, I further confine my research in \textit{match-based video games}~\cite{guo2012analysis}, where game outcomes become match outcomes restricted to win and lose (and draw if the game allows). These games are played highly competitively match after match; a match refers to a small time session during which multiple players, often random online players, compete for a defined goal of victory. Each match is independent from each other, in the sense that in-game elements get refreshed at the beginning of each match so that every participant starts from a relatively similar state. Match-based video games also imply there are multiple players involved. While the player to whom is to be recommended in-game elements should be a human player, we allow other involved players to be either computer controlled or other human players. Match-based video games represent a wide range of genres and titles, ranging from one-vs-one online \textit{Chess} to team-based games like \textit{League of Legends}, arguably having more variety in player interactions and strategies than single-player games such as \textit{Tetris}. Thus, match-based video games provide a representative and interesting test bed for studying recommendation systems.

% Based on the number of human player participants, video games can be categorized as single-player and multi-player game. The former puts the single player against pre-programmed challenges or AI-controlled opponents, while the latter allows player interaction with other individuals in partnership, competition or rivalry. Player-versus-Player (PvP) is one mode in which multiple players (who may form as teams) directly engage in competition or combat. PvP games are usually played match after match. 



Moreover, I focus on recommendation systems which are applied in the \textit{pre-match} stage in match-based video games. Generally, recommendation systems for these games can run in either \textit{pre-match stage} or \textit{mid-match stage} to influence match outcomes. Pre-match stage is the time window from the moment a player requests to start a match until the match officially begins. Depending on the nature of the game, there are various in-game elements to be determined before the match can officially starts, such as opponents, characters to be played throughout the match, and starting items to bring into the match. In-match stage is the period when the real match takes place and players engage in competition. I choose the scope of my thesis to be within \textit{the pre-match stage} because it is the initial, yet fundamental, gateway into the main experience of the match. Bad determination of in-game elements in the pre-match stage may put certain players into disadvantages from the beginning of the match and could lead to toxic behaviors such as quitting the match early~\cite{shores2014identification} and cyberbullying~\cite{kwak2015exploring}. 

All my justified choices finally lead to the fundamental research question of this thesis:

\begin{displayquote}
How can we use recommendation systems to influence game outcomes in the pre-match stage in multi-player match-based video games as a means of keeping players engaged ?
\end{displayquote}

% Hence, fairness-based matchmaking systems for opponent recommendation have been thus designed to create competitive matches~\cite{herbrich:trueskill,myslak2014developing}, based on various skill models that accurately estimate player skills~\cite{glickman1999parameter,elo1978rating,herbrich:trueskill}. 

My thesis outlines three recommendation systems under the umbrella of this question, with each system tackling problems for a specific type of in-game element, namely starting items, characters, and opponents. In the following section, I will introduce what each recommendation system tries to solve, and their connections with each other for answering my research question.

\section{Thesis Overview}\label{sec:thesis_overview}

\subsection{Starting Item Recommendation}\label{sec:thesis_overview:item_recom}

Starting items are those players designate to bring into a match before the match starts. In-match strategies and play styles could largely depend on the choice of the starting items. Thus, starting items could have an important impact on match outcomes. Today's video games usually have very rich design to offer players endless replayability. As such, there can be a large number of candidate items to be selected from to build the starting item set and it is often beyond inexperienced players' ability to make good decision for adapting to their situations (e.g., skills and opponents). To this end, I propose a starting item recommendation system that can aid players efficiently identify the most winning-effective starting item set against an input opponent stereotype from a large amount of candidate starting items. 

Our test bed of the starting item recommendation system is a one-vs-one \textit{Collectible Card Game} (CCG). CCG is a popular genre belonging to match-based video games; digital CCGs like \textit{Hearthstone} reached a record of 40 million registered accounts in 2016~\cite{hearthstonepopular}. In a CCG, the starting items refer to the \textit{deck}, a fixed number of cards (usually just a few dozens) that every player is asked to select from a pool of cards (usually a few hundreds). Ideally, a winning-effective deck should contain cards which have synergies with each other and effective oppositions against the cards in the opponent's deck. CCGs feature the challenge that the number of possible deck choices is exponentially large such that seeking for winning-effective decks in an efficient manner is difficult. For example, in the particular game we study, which we will detail in Chapter~\ref{chapter:qdeckrec}, the number of all possible decks is around $1.4 \times 10^{25}$. 

The proposed deck recommendation system first extracts a deck building policy from a large number of simulation-based deck evaluations in a training phase. The policy encodes card synergy and opposition relationships into a parameterized machine learning model and can be used to construct the (approximately) most winning-effective deck based on an given input opponent stereotype. The computation involved in calling the deck building policy is cheap enough for the proposed system to be deployed for large-scale or real-time application, e.g., an online CCG's backend to recommend winning-effective decks to a population of online players, a deck analysis website to serve hundreds of online visitors' deck building requests, or large-scale deck balancing tests. 

% Each new deck recommendation request will then only need to call the parameterized machine learning model with the input opponent stereotype for obtaining the winning-effective deck without needing to evaluate candidate decks' strength by simulations in real-time.

% Existing solutions for deck recommendation mainly fall into two categories: heuristic searches and metaheuristic searches~\cite{birattari2009tuning}. However they are still insuitable as practical recommendation systems. Heuristic search methods decide which cards to include based on domain heuristics such as popularity and in-game resource curve~\cite{frankkarsten,willfancher,stiegler2016hearthstone}. However, heuristic methods require in-depth human knowledge and lack flexibility to adapt to different opponents. Another category is metaheuristic search, referring to high-level, problem-independent, approximate search strategies for tackling optimization problems~\cite{birattari2009tuning}. An example is to use a \textit{Genetic Algorithm} (GA)~\cite{holland1992adaptation} to evolve decks towards higher winning-effectiveness through repeated modifications and selections~\cite{garcia2016evolutionary,bjorke2017deckbuilding}. Although metaheuristic search algorithms do not require human knowledge to guide searches, they require a large computational cost for each deck recommendation request because: (1) the search process requires a number of evaluations of candidate decks; (2) the evaluation of a candidate deck's quality is computationally expensive, as this requires a large number of simulated matches with complicated in-game rules. 

% Aiming to eliminate the computationally expensive deck evaluation in meta-heuristic methods, my proposed deck recommendation system adds a training phase where a deck building policy is extracted from a large number of deck evaluations. The policy encodes card synergy and opposition relationships into a parameterized machine learning model. Each deck recommendation request will then only need to call the parameterized machine learning model, together with the input opponent stereotype, for obtaining the winning-effective deck. Since the calculation involved in deck building policy requires much cheaper computation resources than deck evaluations, the proposed deck recommendation system is suitable to deploy for large-scale or real-time application, e.g., an online CCG's backend to recommend winning-effective decks to a population of online players, a deck analysis website to serve hundreds of online visitors' deck building requests, or large-scale deck balancing tests. The deck recommendation system exemplifies how we can influence match outcomes positively for one side of a match and how we can locate the winning-optimal start items efficiently for large-scale or real-time application. 


% Garc{\'\i}a-S{\'a}nchez et al.~\cite{garcia2016evolutionary} proposed to use \textit{Evolutionary Algorithm} (EA)~\cite{eiben2003introduction} inspired by natural evolution to search for the most competent deck from repeatedly filtering of randomly modified candidate decks. The filtering criteria is based on the \textit{fitness value} defined as the average win rate of a candidate deck pitting against the stereotyped opponent deck. A default, greedy-based AI was used as a proxy of strategy executor for both sides. However, the limitation of their method is that a deck's strength may not be completely realized by just using the universal, greedy-based AI. In real-world matches, there exist many advanced strategies that the greedy-based AI fails to execute, e.g., wait until two cards are drawn to the hand to make combined play. Moreover, as pointed out by Garc{\'\i}a-S{\'a}nchez et al.~\cite{garcia2016evolutionary}, the evolution of candidate decks is currently totally random rather than following a more effective, human-like deck modification. For example, rather than randomly replacing a card with another card, human players do not break up well-known good card combinations  or replace a card with a similar but much weaker one. The "blindness" of EA hinders its speed to converge to a competitive deck, given the nature of exponentially large choices. Therefore, we propose to improve the effectiveness of the existing recommendation method hence more practical on influencing match outcomes: (1) search decks more intelligently; (2) replace the universal, greedy-based AI with more advanced AI that can realize useful strategies of a given deck. The initial item recommendation system exemplifies \textit{how} match outcomes can be affected positively \textit{from one side}.

\subsection{Character Recommendation}\label{sec:thesis_overview:character_recom}
In certain games, selecting a suitable game character in the pre-match phase is also a key to victory. This is because different characters, like starting items, are designed with various in-game abilities and roles, on which in-game play styles and strategies will largely depend. What we investigate further compared to the starting item recommendation system is on recommending winning-effective characters in the context of \textit{team-based} games, where a large amount of character interactions between teammates or opponents' characters could influence match outcomes~\cite{pobie1,Semenov2016,kim2016proficiency} but often not be comprehended well by inexperienced players.


We choose to study character recommendation in team-based games using Multi-Player Online Battle Arena (MOBA) Games as a testbed. MOBA has been one of the most popular e-sports game types~\cite{superdata2016}. In a MOBA match, two teams, composed of 5 players each, combat in a virtual environment; each player controls a character to co-operate with other teammates in attacking opponents' characters, armies, and structures, while defending their own in-game properties. In most famous MOBA games like \textit{League of Legends} and \textit{DOTA 2}, there are possibly more than 100 characters that can be picked by a player at the pre-match selection phase. As estimated by~\cite{hanke2017reco}, the number of total possible team compositions (10 characters in a match) is approximately $1.56 \times 10^{16}$. What increases the difficulty of winning-effective character recommendation is the order of character selection: the two teams alternate to pick characters in a certain order (varied upon specific match modes) until every player gets one character selected. In order to pick a winning-effective character, a player not only needs to know complicated synergistic and oppositional relationships among characters, but should also well predict what characters will be selected by other players and how they will affect his choice. 

% Heroes can only be selected from a fixed pool and no duplication is allowed in the same match. Note that the drafting rules described here are based on ``Ranked All Pick'', a popular match mode in DOTA 2. For simplicity of illustration, we will first focus on this kind of match and its drafting process. There are other more sophisticated mechanics deployed in the drafting process that may affect match outcomes, such as \textit{banning} (i.e., certain heroes can be prohibited from selection by either team), which we will study in the end of our performance evaluation (Section~\ref{sec:extension}).

% Game avatar selection takes place before the match starts. The order of game avatar selection varies across different game modes. In some modes, players select game avatars alternating between the two teams, while in other modes all players can freely choose game avatars within a short time window. Some modes also prohibit from selecting duplicated game avatars. In some modes, certain game avatars can be banned by the other side from being selected. No matter in what game modes players are, game avatar recommendations will be helpful to players' decision making especially for those who already know which game avatars selected by teammates and opponents.

% Game avatars are often designed with a variety of attributes, skills, roles, etc., which is intended to provide players with choices and options so that every player can find a game avatar that fits their preferences. Moreover, it is customary for game avatars in such games to possess strength in one aspect, but weakness in others. For example, in DOTA 2 (Valve Corporation), game avatars with the \textit{Agility} attribute such as \textit{Anti-Mage} excel in long-range physical damage but are susceptible in face-to-face combats. In contrast, with sturdier armor, those of the \textit{Strength} attribute such as \textit{Axe} can tolerate large damage in direct confrontation but lack strong attack ability. As such, in order to win a match, players need to not only control their own game avatars well, but also need to select a game avatar that, together with other team members' picks, forms a team with as few weaknesses as possible, while posing suppressing strengths over those in the opponent team~\cite{kim2016proficiency}.

We view the character selection phase between two teams as a \textit{combinatorial\linebreak game}~\cite{browne2012survey}. Under this problem formulation, the winning-optimal character for a player is the one that leads to the character line-up with the largest predicted win rate on its team, assuming that both teams behave optimally in the remaining of the character selection phase.  We propose a character recommendation system that is able to efficiently identify the approximated winning-optimal character for team victory while considering the character selection strategies adopted by other players. The proposed system utilizes an efficient search algorithm called Monte Carlo Tree Search (MCTS)~\cite{kocsis2006bandit}, which could estimate the \textit{long-term value} of each character candidate through efficiently simulating possible following character selections. 

% Each hero-lineup is associated with a reward, defined as a predicted team win rate representing the estimated strength of the hero line-up. MCTS then back-propagates the reward to update the values of simulated picks. As more simulations are executed, the estimated values become more accurate, allowing MCTS to identify the next pick optimal for team victory. 

% The specific version of MCTS~\cite{kocsis2006bandit} we use, namely Upper Confidence Bound applied to Trees, or UCT, is an \textit{anytime} algorithm, i.e., it has the theoretical guarantee to converge to the optimal pick given sufficient time and memory, while it can be stopped at any time to return an approximate solution. In contrast, previous works either predict player tendency to pick heroes~\cite{summerville2017reco}, or leverage association rules mined from historical hero line-ups as heuristics~\cite{hanke2017reco}. They are not guaranteed to converge to the optimal hero pick for team victory.



\subsection{Opponent Recommendation}\label{sec:thesis_overview:oppo_recom}

The opponent is an indispensable element in match-based video games, either controlled by computer programs or other human players. When there are a population of online human players queuing to play an online match-based video game, we usually rely on an opponent recommendation system, also known as a matchmaking system, to connect them and divide them into individual matches. 

A common strategy of current practical opponent recommendation systems is creating fair matches, that is, to create matches with hard-to-predict match outcomes. This strategy relies on the qualitative assumption that matching closely skilled players tend to create competitive environments that enhance player engagement~\cite{sweetser2005gameflow,flow1990psychology,chen2007flow,graepel2006ranking}. Such opponent recommendation systems essentially use only one dimension of personal information - player skill. However, this fundamental, yet intuitive, assumption is worthy of deep investigation. In fact, fair match outcomes may not be suitable to all types of players at all times. Consider a cautious player who cares about protecting his rank among friends, and a risk taker who enjoys difficult matches. Pairing them with the similarly skilled opponents will affect these players very differently. Even for the same player, their expectation on the coming match when they just lost three games in a row can be very different from that when they recently performed well. These intuitions lead to two key motivations: (1) it will be good if recommended opponents can complement each other's conscious or subconscious needs to engage in the game; and (2) opponent recommendation should depend on dynamic and individual \emph{player states} besides player skills.

We will show that the long-held belief to always create skill-fair matches for all players is worth revisiting. We therefore propose an opponent recommendation system which can model player with richer information besides skill, and instead of always creating matches with hard-to-predict outcomes, the recommended opponents are predicted to result in match outcomes beneficial to the engagement of the total waiting player population to the best extent, where the player engagement is measured by a data-driven approach. Currently, the proposed opponent recommendation system work in one-vs-one games but we will show that it can be extended to team-vs-team games if certain component of the system can be further studied and upgraded.  



% Next, we would like to study opponent recommendation to influence match outcomes of a population of pre-match players who are waiting to start matches. In PvP matches, when some players win, the other players lose. We cannot let every player win and enjoy the victory in every match. We choose the criteria of opponent recommendation as to optimize the overall engagement of the pre-match player population. 


% In Table~\ref{tab:churnrate}, we show an example that churn risks vary drastically upon players' recent match outcomes in a real-world popular PvP game. Here, churn risk, a common quantitative measurement of player engagement, is the ratio of the players who stop playing within a period time after a match. These facts lead to three key motivations: (1) it will be good if recommended opponents can complement each other's conscious or subconscious needs to engage in the game; and (2) opponent recommendation should depend on dynamic and individual \emph{player states} besides player skills. Thus, our plan is to develop an opponent recommendation framework that recommend opponents depending on player states in order to optimize the overall engagement, addressing both \textit{how} and \textit{how much} match outcomes should be affected for \textit{a population of players}.



\subsection{Connections between Three Recommendation Systems}
% We cannot let every player win and enjoy the victory in every match. 

My thesis revolves around three recommendation systems, i.e., the starting item, character and opponent recommendation systems, for answering the research question raised in the end of Section~\ref{chap1:motiv}. The starting item and character recommendation systems exemplify \textit{how} we can influence match outcomes positively for one player in a one-vs-one setting and team-vs-team setting, respectively. They both face the challenge to efficiently filter the winning-effective in-game elements from a large number of possibilities. These two systems can work together with other systems to decide when to trigger their recommendations for helping individual players engage in the game. Thus, they can be treated as \textit{indirect} ways to influence player engagement. However, we also note that due to the nature of match-based video games, when some players win, the other players lose. When multiple players are in need of our recommendations to improve their win rate, there must be certain criteria for solving this conflict. In our opponent recommendation system, we choose the criterion as to optimize the overall engagement of the player population, thus it addresses both \textit{how} and \textit{how much} we should influence match outcomes for a population of players. The opponent recommendation is considered as a \textit{direct} means to influence player engagement.

There are also several practical reasons for my thesis taking into accounts these three recommendation systems. First, starting items, characters and opponents are all commonly seen in-game elements in match-based video games and could have a large impact on today's video game landscape.  Second, the author spent significant efforts in data collection during his research collaboration and industry internships to make relevant data and software tools available. The difficulty of accessing to sensitive game data and software tools limits our current research scope to these recommendation systems. Third, existing relevant solutions for these recommendation systems are so far scarce and in much infancy, showing much room for improvement. 

\subsection{Contributions and Results}
The thesis contributes to the research in recommendation systems for video games in the following aspects:
\begin{itemize}
\item \textbf{A starting item recommendation system for one-vs-one games}. We apply the system for finding  winning-effective decks in Collectible Card Games (CCGs). We propose \textit{Q-DeckRec}, an algorithm which learns a
search policy for finding highly winning-effective decks quickly. We conduct experiments to show that after a training phase Q-DeckRec is
able to build a highly winning-effective deck for each deck recommendation request within CPU time short enough for large-scale or real-time application, which is not achievable by existing solutions. The proposed recommendation system has been previously published as ``Q-DeckRec: a Fast Deck Recommendation System for Collectible Card Games'', in \textit{2018 IEEE Conference on Computational Intelligence and Games (CIG'18)}~\cite{chenqdeckrec}.
\item \textbf{A character recommendation system for team-vs-team games}. We apply the system for recommending winning-effective characters in Multi-player Online Battle Arena (MOBA) Games. We provide a formal formulation of the character selection process in MOBA games as a combinatorial game. We propose a character recommendation approach to solve the above problem using a Monte Carlo Tree Search (MCTS) algorithm. We conduct empirical simulation experiments, demonstrating the proposed system's superior capability of recommending winning-effective characters over other baseline and state-of-the-arts strategies. This work has been submitted to a conference and under peer review.
\item \textbf{An opponent recommendation framework for general match-based video games}. We
propose an engagement optimized opponent recommendation framework which solves opponent recommendation as an optimization problem of maximizing the overall player engagement. We provide theoretical analysis about the optimality of and the conditions of the applicability of the proposed system and other existing methods. We build a simulated system using real game data to show significant advantages of the proposed opponent recommendation system in retaining players over existing methods. The proposed system has been previously published as "EOMM: An Engagement Optimized Matchmaking Framework", in \textit{Proceedings of the 2017 International Conference on World Wide Web (WWW'17)}~\cite{chen2017eomm}.
\end{itemize}


\subsection{Thesis Outline}
The rest of the thesis will be structured as follows. 
\begin{itemize}
\item Chapter~\ref{chapter:relatework} introduces backgrounds and existing works relevant to my research. 
\item Chapter~\ref{chapter:qdeckrec} \textasciitilde  Chapter~\ref{chapter:eomm} introduce the three proposed recommendation systems, \textit{Q-DeckRec}, \textit{DraftArtist}, and \textit{EOMM} , respectively.
\item Chapter~\ref{sec:conclusion} concludes the thesis and points out future directions for extending this thesis.
\end{itemize}

